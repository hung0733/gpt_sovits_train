import logging
import os
from pathlib import Path
import librosa
import numpy as np
import noisereduce as nr
from pydub import AudioSegment
from datetime import timedelta
import io
import soundfile as sf

from config import Config
from structure import Task
from tools.tools import Tools



class Slice:
    @staticmethod
    def get_slick_audio_task() -> Optional[Task]: # è¨˜å¾— import Optional
        base_dir = Config.dirs["TRAIN_INPUT"]
        if not base_dir.exists():
            logging.warning(f"Input ç›®éŒ„ä¸å­˜åœ¨: {base_dir}")
            return None

        for sub_dir in sorted(base_dir.iterdir()):
            if not sub_dir.is_dir():
                continue

            char_name = sub_dir.name
            
            for audio_dir in sorted(sub_dir.iterdir()):
                if not audio_dir.is_dir():
                    continue

                audio_name = audio_dir.name
                vocal_path = audio_dir / "vocal_main_vocal.wav"
                result_dir: Path = audio_dir / "slice"

                # --- ä¿®æ­£å¾Œçš„ Check é‚è¼¯ ---
                # 1. ä¾†æºæª”æ¡ˆå¿…é ˆå­˜åœ¨
                if not vocal_path.exists():
                    continue
                
                # 2. åˆ¤æ–·æ˜¯å¦éœ€è¦åŸ·è¡Œ Slice:
                #    å¦‚æœ slice è³‡æ–™å¤¾å””å­˜åœ¨ OR å…¥é¢ä¿‚ç©ºå˜…
                is_empty = True
                if result_dir.exists():
                    # any(result_dir.iterdir()) å¦‚æœå…¥é¢æœ‰ä»»ä½• file æœƒå›å‚³ True
                    if any(result_dir.iterdir()):
                        is_empty = False

                if is_empty:
                    return Task(
                        cmd="Slice_Audio",
                        sub_cmd="",  # å‘¢åº¦è£œè¿”å°±å””æœƒå ± Pydantic validation error
                        file_path=vocal_path,
                        character_name=char_name,
                        audio_name=audio_name,
                    )
        return None
                                  
    @staticmethod
    def process_slick_audio_task(task: Task):
        if not task.in_process:   
            task.to_file(Config.train_task_file)
            
        Tools.clear_folder_contents(task.slice_dir)
        Slice.slice_and_denoise(str(task.file_path), str(task.slice_dir))
    
    @staticmethod
    def _format_timestamp(ms):
        """å°‡æ¯«ç§’è½‰æˆ HHMMSSms æ ¼å¼"""
        td = timedelta(milliseconds=ms)
        total_seconds = int(td.total_seconds())
        hours, remainder = divmod(total_seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = int(td.microseconds / 1000)
        return f"{hours:02d}{minutes:02d}{seconds:02d}{milliseconds:03d}"

    @staticmethod
    def slice_and_denoise(input_file, output_dir, min_sec=4, max_sec=10, gap_threshold_sec=1.0, top_db=35):
        os.makedirs(output_dir, exist_ok=True)

        logging.info(f"ğŸš€ å•Ÿå‹•é™å™ª + æ‹†åˆ†æµç¨‹...")
        
        # 1. è¼‰å…¥éŸ³è¨Š
        y, sr = librosa.load(input_file, sr=None)
        
        # 2. åŸ·è¡Œé™å™ª
        logging.info("ğŸ§¹ æ­£åœ¨é€²è¡Œ AI é™å™ªè™•ç†...")
        # åŠ å…¥ stationary=True é€šå¸¸å° UVR5 å‰©ä½å˜…åº•å™ªæ•ˆæœæ›´å¥½æ›´ç©©å®š
        y_denoised = nr.reduce_noise(y=y, sr=sr, prop_decrease=0.8, stationary=True)
        
        # ä¿®æ­£ï¼šè™•ç† NaN æ•¸å€¼é˜²æ­¢è½‰æ›å´©æ½°
        y_denoised = np.nan_to_num(y_denoised)

        # 3. å°‡é™å™ªå¾Œå˜…æ•¸æ“šè½‰åš pydub ç‰©ä»¶ (ç”¨ BytesIO æ¯”è¼ƒç©©é™£)
        logging.info("å­˜å„²è‡¨æ™‚éŸ³è¨Š...")
        buffer = io.BytesIO()
        sf.write(buffer, y_denoised, sr, format='WAV')
        buffer.seek(0)
        audio = AudioSegment.from_file(buffer)

        # 4. æµå‡ºã€Œæœ‰è²å€é–“ã€
        # æé«˜ top_db (e.g., 30) å¦‚æœä»²ä¿‚æµå””åˆ°è²ï¼›é™ä½ (e.g., 40) å¦‚æœåˆ‡å¾—å¤ªç¢
        intervals = librosa.effects.split(y_denoised, top_db=top_db)
        
        if len(intervals) == 0:
            logging.info(f"âŒ ä¾èˆŠæµå””åˆ°äººè²ã€‚è©¦å“å°‡ top_db è¼ƒä½å•² (è€Œå®¶ä¿‚ {top_db})")
            return

        final_segments = []
        curr_start_ms = int(intervals[0][0] / sr * 1000)
        curr_end_ms = int(intervals[0][1] / sr * 1000)

        # 5. æ–·å¥é‚è¼¯ (1ç§’ç©ºç™½å¿…æ–·)
        for i in range(1, len(intervals)):
            next_start_ms = int(intervals[i][0] / sr * 1000)
            next_end_ms = int(intervals[i][1] / sr * 1000)
            
            gap_duration = next_start_ms - curr_end_ms
            current_total_duration = next_end_ms - curr_start_ms

            if gap_duration >= gap_threshold_sec * 1000 or current_total_duration > max_sec * 1000:
                if curr_end_ms - curr_start_ms >= 1000:
                    final_segments.append((curr_start_ms, curr_end_ms))
                curr_start_ms = next_start_ms
                curr_end_ms = next_end_ms
            else:
                curr_end_ms = next_end_ms

        if curr_end_ms - curr_start_ms >= 1000:
            final_segments.append((curr_start_ms, curr_end_ms))

        # 6. å°å‡ºæª”æ¡ˆ
        logging.info(f"âœ‚ï¸ æº–å‚™å°å‡º {len(final_segments)} æ®µä¹¾æ·¨ç‰‡æ®µ...")
        count = 0
        for start, end in final_segments:
            if (end - start) < 2000: continue
            
            chunk = audio[start:end]
            chunk = chunk.set_frame_rate(44100).set_channels(1).set_sample_width(2)
            
            filename = f"{_format_timestamp(start)}.wav"
            save_path = os.path.join(output_dir, filename)
            chunk.export(save_path, format="wav")
            logging.info(f"  âœ¨ å·²å°å‡º: {filename} ({ (end-start)/1000 }s)")
            count += 1

        logging.info(f"\nğŸ‰ ä»»å‹™å®Œæˆï¼æˆåŠŸåˆ‡å‡º {count} æ®µã€‚")

if __name__ == "__main__":
    TARGET = "/mnt/data/misc/tts/train/input/F001/1/vocal_main_vocal.wav" 
    OUTPUT = "/tmp/slice_audio"
    
    slice_and_denoise(TARGET, OUTPUT, top_db=30) # ç¨å¾®èª¿ä½ top_db ç­‰ä½¢æ˜“å•²æµåˆ°è²